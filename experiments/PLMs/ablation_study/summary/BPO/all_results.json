{
  "01_full_model": {
    "ablation_name": "01_full_model",
    "ablation_description": "Full model with all components",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 7901853,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": true,
      "use_interaction": true,
      "use_diversity_loss": false,
      "use_gate_entropy": true,
      "learnable_temperature": true,
      "temperature": 1.5,
      "gate_entropy_weight": 0.001
    },
    "test_metrics": {
      "fmax": 0.5087950406319092,
      "threshold": 0.43565656565656563,
      "precision": 0.5131947306342274,
      "recall": 0.5044701477942607,
      "micro_auprc": 0.5015359656978672,
      "macro_auprc": 0.17629138863753288,
      "text_mean": 0.5364823937416077,
      "text_std": 0.07088615745306015,
      "prott5_mean": 0.46351760625839233,
      "prott5_std": 0.07088615745306015,
      "cafa_fmax": 0.582,
      "cafa_threshold": 0.58,
      "cafa_precision": 0.62,
      "cafa_recall": 0.548,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.584,
      "cafa_rc_micro": 0.448,
      "cafa_f_micro": 0.507,
      "cafa_smin": 18.994
    },
    "best_val_fmax": 0.5165652370479902,
    "best_epoch": 15,
    "total_epochs": 20,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  },
  "02_no_gate_adjuster": {
    "ablation_name": "02_no_gate_adjuster",
    "ablation_description": "Remove gate adjustment mechanism",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 7638939,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": false,
      "use_interaction": true,
      "use_diversity_loss": false,
      "use_gate_entropy": true,
      "learnable_temperature": true,
      "temperature": 1.5,
      "gate_entropy_weight": 0.001
    },
    "test_metrics": {
      "fmax": 0.5070631130797072,
      "threshold": 0.41585858585858587,
      "precision": 0.5120429586793332,
      "recall": 0.5021791970497017,
      "micro_auprc": 0.4933994788666385,
      "macro_auprc": 0.18040805627122997,
      "text_mean": 0.49310746788978577,
      "text_std": 0.05670393258333206,
      "prott5_mean": 0.5068925619125366,
      "prott5_std": 0.05670393258333206,
      "cafa_fmax": 0.575,
      "cafa_threshold": 0.48,
      "cafa_precision": 0.561,
      "cafa_recall": 0.589,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.527,
      "cafa_rc_micro": 0.49,
      "cafa_f_micro": 0.508,
      "cafa_smin": 19.431
    },
    "best_val_fmax": 0.5171528905214442,
    "best_epoch": 17,
    "total_epochs": 22,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  },
  "03_fixed_temperature": {
    "ablation_name": "03_fixed_temperature",
    "ablation_description": "Fixed temperature (not learnable)",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 7901852,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": true,
      "use_interaction": true,
      "use_diversity_loss": false,
      "use_gate_entropy": true,
      "learnable_temperature": false,
      "temperature": 1.5,
      "gate_entropy_weight": 0.001
    },
    "test_metrics": {
      "fmax": 0.5126663803708109,
      "threshold": 0.44555555555555554,
      "precision": 0.5255744343692219,
      "recall": 0.5003771687201402,
      "micro_auprc": 0.4915130822366323,
      "macro_auprc": 0.17567708998941867,
      "text_mean": 0.5422093868255615,
      "text_std": 0.06531475484371185,
      "prott5_mean": 0.45779067277908325,
      "prott5_std": 0.06531475484371185,
      "cafa_fmax": 0.584,
      "cafa_threshold": 0.58,
      "cafa_precision": 0.617,
      "cafa_recall": 0.553,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.58,
      "cafa_rc_micro": 0.452,
      "cafa_f_micro": 0.508,
      "cafa_smin": 19.047
    },
    "best_val_fmax": 0.5175743210300522,
    "best_epoch": 17,
    "total_epochs": 22,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  },
  "04_no_interaction": {
    "ablation_name": "04_no_interaction",
    "ablation_description": "Remove cross-modal interaction layer",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 6852765,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": true,
      "use_interaction": false,
      "use_diversity_loss": false,
      "use_gate_entropy": true,
      "learnable_temperature": true,
      "temperature": 1.5,
      "gate_entropy_weight": 0.001
    },
    "test_metrics": {
      "fmax": 0.5066761464128664,
      "threshold": 0.4257575757575757,
      "precision": 0.5159272558786046,
      "recall": 0.4977509568910115,
      "micro_auprc": 0.4855219759130347,
      "macro_auprc": 0.18222248760109108,
      "text_mean": 0.5066846013069153,
      "text_std": 0.07374288141727448,
      "prott5_mean": 0.49331536889076233,
      "prott5_std": 0.07374288141727448,
      "cafa_fmax": 0.578,
      "cafa_threshold": 0.55,
      "cafa_precision": 0.594,
      "cafa_recall": 0.562,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.557,
      "cafa_rc_micro": 0.46,
      "cafa_f_micro": 0.504,
      "cafa_smin": 19.392
    },
    "best_val_fmax": 0.517912898582765,
    "best_epoch": 26,
    "total_epochs": 31,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  },
  "05_no_gate_entropy": {
    "ablation_name": "05_no_gate_entropy",
    "ablation_description": "Remove gate entropy regularization",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 7901853,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": true,
      "use_interaction": true,
      "use_diversity_loss": false,
      "use_gate_entropy": false,
      "learnable_temperature": true,
      "temperature": 1.5
    },
    "test_metrics": {
      "fmax": 0.512661045767232,
      "threshold": 0.4257575757575757,
      "precision": 0.5188024774355959,
      "recall": 0.5066633140558202,
      "micro_auprc": 0.5009471188677342,
      "macro_auprc": 0.1826505022400224,
      "text_mean": 0.43892034888267517,
      "text_std": 0.0832347571849823,
      "prott5_mean": 0.5610796809196472,
      "prott5_std": 0.0832347571849823,
      "cafa_fmax": 0.586,
      "cafa_threshold": 0.54,
      "cafa_precision": 0.598,
      "cafa_recall": 0.574,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.56,
      "cafa_rc_micro": 0.469,
      "cafa_f_micro": 0.511,
      "cafa_smin": 19.186
    },
    "best_val_fmax": 0.5166577744032433,
    "best_epoch": 17,
    "total_epochs": 22,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  },
  "09_with_diversity_loss": {
    "ablation_name": "09_with_diversity_loss",
    "ablation_description": "Full model + diversity loss",
    "modality_pair": "text_prott5",
    "aspect": "BPO",
    "num_go_terms": 3992,
    "num_parameters": 7901853,
    "seed": 42,
    "model_config": {
      "use_adaptive_gates": true,
      "use_gate_adjuster": true,
      "use_interaction": true,
      "use_diversity_loss": true,
      "diversity_weight": 0.01,
      "use_gate_entropy": true,
      "learnable_temperature": true,
      "temperature": 1.5,
      "gate_entropy_weight": 0.001
    },
    "test_metrics": {
      "fmax": 0.5182626080960904,
      "threshold": 0.46535353535353535,
      "precision": 0.546922754704686,
      "recall": 0.4924566255971831,
      "micro_auprc": 0.5074179850761382,
      "macro_auprc": 0.17760494257741255,
      "text_mean": 0.5689459443092346,
      "text_std": 0.06607603281736374,
      "prott5_mean": 0.4310540556907654,
      "prott5_std": 0.06607603281736374,
      "cafa_fmax": 0.592,
      "cafa_threshold": 0.59,
      "cafa_precision": 0.639,
      "cafa_recall": 0.551,
      "cafa_coverage": 1.0,
      "cafa_pr_micro": 0.603,
      "cafa_rc_micro": 0.45,
      "cafa_f_micro": 0.516,
      "cafa_smin": 18.663
    },
    "best_val_fmax": 0.5176690675289624,
    "best_epoch": 17,
    "total_epochs": 22,
    "dataset_sizes": {
      "train": 47691,
      "val": 5252,
      "test": 2392
    }
  }
}